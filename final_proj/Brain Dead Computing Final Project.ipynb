{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Brain Dead Computing Final Project.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"nhG4GGwyjtiY"},"source":["# **Planned Structure:** Remove before submission\n","\n","\n","\n","**input layer**: \n","*   Basically take the images and convert the greyscale image into an array and then pass it directly into convolutional layers\n","\n","\n","\n","\n","**Convolutional layers**: we have 2 layers of many kernels where stride = 1\n","\n","\n","*   Layer 1: 100 3x3 kernels - maybe add pooling after (idk if good or na)\n","*   Layer 2: 50 3x3 kernels\n","*   Layer 3: pooling: leaning towards avg pooling but we can max pool idc\n","*   Referenced: [Face Mask Detection using CNN in Python | by Arbalest Partners](https://arbalestpartners.medium.com/face-mask-detection-using-cnn-in-python-3148f82dcfe7)\n","\n","\n","\n","\n","\n","**FC layer**: idk the full logistics but here’s roughly what i got so far\n","* rough idea: Upon completing of the convolutions: we then apply the formula explained in idea 1 to determine out constant input for each respective neuron in the input portion of the fc layer\n","*   Neuron type: Leaky-Integrate and Fire w focus on neurons firing off based on rate of presynaptic neuron fire rate \n","*   Input neurons: whatever the flattened output size is after final pooling - convert the greyscale value into our constant input current : i(k) = Io * (k * Ip) where i(k) = the constant input current we are looking to calculate, Io = 2700 pA, k = greyscale pixel value [0, 255], Ip= 101.2 pA - **WE MAY NOT NEED THIS FORMULA SHIT CUZ WE CAN USE LIBARIES**\n","*   Intermediate neurons: i still have no idea how to determine struct of this\n","*   2 output neurons\n","*   Referenced: [Spiking neural networks for handwritten digit recognition—Supervised learning and network optimization ](https://www.sciencedirect.com/science/article/abs/pii/S0893608018301126)\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGTDLubxZtOK","executionInfo":{"status":"ok","timestamp":1607571324644,"user_tz":300,"elapsed":482,"user":{"displayName":"Shyam Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVUadbbp5O-81RTgB9kibzI5P1nM2GLqIpYrcWTA=s64","userId":"04553924193054739110"}},"outputId":"444279b5-5a4b-4070-da0b-9d96300f8515"},"source":["# RE RUN CELL AND SEE IF DATASET AND DATASET.ZIP ARE PRESENT - or check the files tab on the left\n","# IF THEY ARE DON'T RUN THE NEXT CELL - it'll prompt you whether you want to replace each image 1 by 1 20,000 times\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z6lAKSMGsI6X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607150036436,"user_tz":300,"elapsed":10467,"user":{"displayName":"Shyam Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVUadbbp5O-81RTgB9kibzI5P1nM2GLqIpYrcWTA=s64","userId":"04553924193054739110"}},"outputId":"393617e5-9f53-4acf-daad-72e2fc322b7c"},"source":["# ONLY RUN THIS ONCE\n","!apt-get install unzip -qq\n","!wget -q -cO - 'https://onedrive.live.com/download?cid=D9CC4BA72F6E9232&resid=D9CC4BA72F6E9232%215062&authkey=ALYx7sedNfyzqHk' > dataset.zip\n","print(\"Dataset Downloaded\")\n","!unzip -q dataset.zip -d dataset\n","print(\"Dataset Unzipped\\n\")\n","print(\"Current Directory Contents:\")\n","!ls\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dataset Downloaded\n","Dataset Unzipped\n","\n","Current Directory Contents:\n","dataset  dataset.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P6ynfnXhmUW_"},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","import plotly as pt\n","import plotly.graph_objects as go\n","import matplotlib as plt\n","\n","# path to the with_mask folder is './dataset/Edited/with_mask'\n","# path to the without_mask folder is './dataset/Edited/without_mask'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVi4_c-6m1-R"},"source":[""],"execution_count":null,"outputs":[]}]}